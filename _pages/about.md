---
permalink: /
title: "About Me"
excerpt: "Ph.D. Student | Northeastern University"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<div class="intro-block">
  <p>
    I am a second-year Ph.D. student in the College of Engineering at
    <span class="kw">Northeastern University</span>, advised by
    [Prof. Yun Raymond Fu](https://www1.ece.neu.edu/~yunfu/) in the
    <span class="kw">SMILE Lab</span>.
  </p>
  <p>
    Before joining Northeastern, I received my B.S. and M.S. degrees from
    <span class="kw">Xidian University</span>, advised by
    [Prof. Xuefeng Liang](https://web.xidian.edu.cn/xliang/en/index.html).
    During my masterâ€™s studies, I also spent six months at
    <span class="kw">Kyoto University</span>, working with
    [Prof. Takatsune Kumada](https://kdb.iimc.kyoto-u.ac.jp/profile/en.a61c204316cdb5fc.html#display-items_basic-information).
  </p>
  <p class="intro-focus">
    Research interests: <span class="tag">MLLMs</span> and <span class="tag">VLMs</span>,
    with a focus on
    <a class="paper-pill" href="#pub-shield">hallucination detection &amp; mitigation (SHIELD)</a>,
    <a class="paper-pill" href="#pub-dcode">video understanding (D-CoDe)</a>, and
    <a class="paper-pill" href="#pub-mason">layout understanding (MASON)</a>.
  </p>
  <p class="intro-meta">
    <span class="kw">Adobe Research</span> intern, Summer 2025.
  </p>
  <p class="intro-cta">
    <a class="btn-cv" href="../files/cv-yiyang.pdf">Curriculum Vitae</a>
  </p>
</div>


---
# News

<div class="news-container">
  <div class="news-item">
    <span class="news-icon">ðŸ“°</span>
    <span class="news-date">Jan. 2026</span>
    <span class="news-text">One paper <em>SHIELD</em> accepted by <span class="news-venue">ICLR 2026</span></span>
  </div>
  <div class="news-item">
    <span class="news-icon">ðŸ“°</span>
    <span class="news-date">Aug. 2025</span>
    <span class="news-text">One paper <em>D-CoDe</em> accepted by <span class="news-venue">EMNLP 2025</span></span>
  </div>
</div>

---
# Publications ([Google Scholar](https://scholar.google.com/citations?user=A0H2ZYQAAAAJ))

<div class="pub-item" id="pub-mason">
  <div class="pub-thumb">
    <img src="/images/pub_mason.png" alt="MASON" onerror="this.style.display='none'">
  </div>
  <div class="pub-content">
    <div class="pub-title">MASON: Compositional Design Layout Understanding in VLMs through Multimodal Alignment and Structural Perception</div>
    <div class="pub-authors"><strong>Yiyang Huang</strong>, Zhaowen Wang, Simon Jenni, Jing Shi, Yun Fu</div>
    <div class="pub-venue"><em>CVPR under-review</em></div>
  </div>
</div>

<div class="pub-item" id="pub-shield">
  <div class="pub-thumb">
    <img src="/images/pub_shield.png" alt="SHIELD" onerror="this.style.display='none'">
  </div>
  <div class="pub-content">
    <div class="pub-title">SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense</div>
    <div class="pub-authors"><strong>Yiyang Huang</strong>, Liang Shi, Yitian Zhang, Yi Xu, Yun Fu</div>
    <div class="pub-venue"><em>International Conference on Learning Representations (ICLR)</em>, 2026</div>
    <div class="pub-links">
      <a href="https://arxiv.org/abs/2510.16596" class="pub-link">ðŸ“„ Paper</a>
      <a href="https://arxiv.org/abs/2510.16596" class="pub-link">ðŸ’» Code</a>
    </div>
  </div>
</div>

<div class="pub-item" id="pub-dcode">
  <div class="pub-thumb">
    <img src="/images/pub_dcode.png" alt="D-CoDe" onerror="this.style.display='none'">
  </div>
  <div class="pub-content">
    <div class="pub-title">D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition</div>
    <div class="pub-authors"><strong>Yiyang Huang</strong>, Yizhou Wang, Yun Fu</div>
    <div class="pub-venue"><em>Empirical Methods in Natural Language Processing (EMNLP)</em>, 2025</div>
    <div class="pub-links">
      <a href="https://arxiv.org/abs/2510.08818" class="pub-link">ðŸ“„ Paper</a>
      <a href="https://github.com/hukcc/D-CoDe" class="pub-link">ðŸ’» Code</a>
    </div>
  </div>
</div>

<div class="pub-item">
  <div class="pub-thumb">
    <img src="/images/pub_lipreading.png" alt="LipReading" onerror="this.style.display='none'">
  </div>
  <div class="pub-content">
    <div class="pub-title">LipReading for Low-resource Languages by Language Dynamic LoRA</div>
    <div class="pub-authors">Shuai Zou, Xuefeng Liang, <strong>Yiyang Huang</strong></div>
    <div class="pub-venue"><em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2025</div>
    <div class="pub-links">
      <a href="https://ieeexplore.ieee.org/abstract/document/10889645" class="pub-link">ðŸ“„ Paper</a>
    </div>
  </div>
</div>

<div class="pub-item">
  <div class="pub-thumb">
    <img src="/images/pub_callip.png" alt="CALLip" onerror="this.style.display='none'">
  </div>
  <div class="pub-content">
    <div class="pub-title">CALLip: Lipreading using Contrastive and Attribute Learning</div>
    <div class="pub-authors"><strong>Yiyang Huang</strong>, Xuefeng Liang, Chaowei Fang</div>
    <div class="pub-venue"><em>ACM International Conference on Multimedia (ACMMM)</em>, 2021</div>
    <div class="pub-links">
      <a href="https://dl.acm.org/doi/10.1145/3474085.3475420" class="pub-link">ðŸ“„ Paper</a>
    </div>
  </div>
</div>

<style>
/* Intro Styles */
.intro-block {
  margin: 0.5em 0 1.2em;
  padding: 0.6em 0 0.2em;
}

.intro-block p {
  margin: 0 0 0.7em;
  line-height: 1.7;
}

.intro-focus {
  margin-top: 0.2em;
}

.intro-meta {
  color: var(--global-text-color-light, #666);
}

.kw {
  font-weight: 600;
  color: var(--global-text-color, #222);
}

.tag {
  display: inline-block;
  padding: 0.15em 0.5em;
  margin-right: 0.4em;
  border-radius: 999px;
  background: rgba(0, 0, 0, 0.06);
  font-weight: 600;
  font-size: 0.9em;
}

.paper-pill {
  display: inline-block;
  margin: 0 0.15em 0.2em 0;
  padding: 0.2em 0.55em;
  border-radius: 999px;
  background: rgba(0, 123, 255, 0.08);
  text-decoration: none;
}

.paper-pill:hover {
  background: rgba(0, 123, 255, 0.15);
  text-decoration: none;
}

.btn-cv {
  display: inline-block;
  padding: 0.45em 0.9em;
  border-radius: 6px;
  background: var(--global-link-color, #007bff);
  color: #fff !important;
  text-decoration: none;
  font-weight: 600;
}

.btn-cv:hover {
  background: var(--global-link-color-hover, #0056b3);
  text-decoration: none;
}

/* News Styles */
.news-container {
  margin: 1em 0;
}

.news-item {
  display: flex;
  align-items: center;
  padding: 0.8em 1em;
  margin-bottom: 0.7em;
  background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
  border-left: 4px solid var(--global-link-color, #007bff);
  border-radius: 0 8px 8px 0;
  line-height: 1.6;
  gap: 0.6em;
}

.news-icon {
  font-size: 1.1em;
}

.news-date {
  font-weight: 700;
  color: #1f2a44;
  background: rgba(0, 0, 0, 0.06);
  padding: 0.1em 0.5em;
  border-radius: 6px;
  letter-spacing: 0.2px;
}

.news-text {
  flex: 1;
}

.news-venue {
  font-weight: 600;
  color: var(--global-link-color, #007bff);
}

/* Publication Styles */
.pub-item {
  display: flex;
  margin-bottom: 1.2em;
  padding: 1.05em;
  background: rgba(128, 128, 128, 0.05);
  border-radius: 8px;
  transition: box-shadow 0.3s ease;
  gap: 1.1em;
}

.pub-item:hover {
  box-shadow: 0 4px 12px rgba(0,0,0,0.15);
}

.pub-thumb {
  flex-shrink: 0;
  width: 160px;
  height: 100px;
  background: rgba(128, 128, 128, 0.1);
  border-radius: 4px;
  overflow: hidden;
  display: flex;
  align-items: center;
  justify-content: center;
}

.pub-thumb img {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

.pub-content {
  flex: 1;
}

.pub-title {
  font-weight: bold;
  font-size: 1em;
  margin-bottom: 0.3em;
  color: var(--global-text-color, #333);
}

.pub-authors {
  font-size: 0.9em;
  color: var(--global-text-color-light, #666);
  margin-bottom: 0.3em;
}

.pub-venue {
  margin-bottom: 0.5em;
}

.pub-links {
  display: flex;
  gap: 0.6em;
  flex-wrap: wrap;
}

.pub-link {
  font-size: 0.85em;
  padding: 0.35em 0.7em;
  background: rgba(0, 123, 255, 0.08);
  color: var(--global-link-color, #007bff) !important;
  border: 1px solid rgba(0, 123, 255, 0.35);
  border-radius: 999px;
  text-decoration: none;
  transition: background 0.2s;
}

.pub-link:hover {
  background: rgba(0, 123, 255, 0.16);
  text-decoration: none;
}
</style>

---
# Academic Service
- **Journal Reviewer**:  
  [ACM Transactions on Knowledge Discovery from Data (TKDD)](https://dl.acm.org/journal/tkdd)  

---
# Honors & Awards

- Outstanding Student, Xidian University, 2022  
- National Scholarship, China, 2021  
- Undergraduate Computer Design Competition (1st Prize), China, 2021  
- RoboMaster National Robotics Competition (2nd Prize), China, 2019  
- ICRA AI Challenge (3rd Prize), 2019  

---
# Teaching Experience

- **Teaching Assistant (TA)**: DS 5110 *Essentials of Data Science*, Fall 2025  

---
# Contact

Email: yiyang.huang.hukcc (at) gmail (dot) com / huang.yiyan (at) northeastern (dot) edu  
WeChat: hukcc369  
